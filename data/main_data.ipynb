{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T22:58:13.017332Z",
     "start_time": "2025-12-23T22:58:11.406143Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load data and convert to metric system (S-JTSK)\n",
    "gdf = gpd.read_file(\"Městské_části.geojson\")\n",
    "gdf = gdf.to_crs(\"EPSG:5514\")\n",
    "\n",
    "# Calculate area in km2\n",
    "gdf['area_km2'] = gdf.geometry.area / 1e6\n",
    "\n",
    "# Rename columns to standard names\n",
    "gdf = gdf.rename(columns={\n",
    "    'nazev_mc': 'district_name',\n",
    "    'kod_mc': 'district_id'\n",
    "})\n",
    "\n",
    "# Keep only relevant columns and sort\n",
    "gdf = gdf[['district_name', 'district_id', 'area_km2', 'geometry']]\n",
    "gdf = gdf.sort_values('district_name').reset_index(drop=True)\n",
    "\n",
    "# Export\n",
    "gdf.to_file(\"prague_districts_mest.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Saved {len(gdf)} districts.\")\n",
    "gdf.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 57 districts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  district_name  district_id   area_km2  \\\n",
       "0       Praha 1       500054   5.538429   \n",
       "1      Praha 10       500224  18.599771   \n",
       "2      Praha 11       547034   9.793681   \n",
       "3      Praha 12       547107  23.317910   \n",
       "4      Praha 13       539694  13.196803   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-743408.143 -1042037.04, -7434...  \n",
       "1  MULTIPOLYGON (((-736946.983 -1043572.498, -736...  \n",
       "2  MULTIPOLYGON (((-738808.792 -1048377.459, -738...  \n",
       "3  MULTIPOLYGON (((-742423.432 -1050304.67, -7424...  \n",
       "4  MULTIPOLYGON (((-750136.923 -1044504.521, -750...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_name</th>\n",
       "      <th>district_id</th>\n",
       "      <th>area_km2</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Praha 1</td>\n",
       "      <td>500054</td>\n",
       "      <td>5.538429</td>\n",
       "      <td>MULTIPOLYGON (((-743408.143 -1042037.04, -7434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Praha 10</td>\n",
       "      <td>500224</td>\n",
       "      <td>18.599771</td>\n",
       "      <td>MULTIPOLYGON (((-736946.983 -1043572.498, -736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Praha 11</td>\n",
       "      <td>547034</td>\n",
       "      <td>9.793681</td>\n",
       "      <td>MULTIPOLYGON (((-738808.792 -1048377.459, -738...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Praha 12</td>\n",
       "      <td>547107</td>\n",
       "      <td>23.317910</td>\n",
       "      <td>MULTIPOLYGON (((-742423.432 -1050304.67, -7424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Praha 13</td>\n",
       "      <td>539694</td>\n",
       "      <td>13.196803</td>\n",
       "      <td>MULTIPOLYGON (((-750136.923 -1044504.521, -750...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T22:58:19.497523Z",
     "start_time": "2025-12-23T22:58:13.060128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "\n",
    "# Define tags for nightlife and tourism\n",
    "tags = {\n",
    "    'amenity': ['bar', 'pub', 'nightclub', 'restaurant', 'cafe'],\n",
    "    'tourism': ['attraction', 'museum', 'hotel', 'hostel']\n",
    "}\n",
    "\n",
    "print(\"Downloading data...\")\n",
    "gdf = ox.features_from_place(\"Prague, Czech Republic\", tags)\n",
    "\n",
    "# Convert to meters first, then calculate centroid (correct way)\n",
    "gdf = gdf.to_crs(\"EPSG:5514\")\n",
    "gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "# Filter points only within Prague boundary\n",
    "mask = ox.geocode_to_gdf(\"Prague, Czech Republic\").to_crs(\"EPSG:5514\").geometry.iloc[0]\n",
    "gdf = gdf[gdf.geometry.within(mask)]\n",
    "\n",
    "# Create a single 'type' column and cleanup\n",
    "gdf['type'] = gdf['amenity'].fillna(gdf['tourism'])\n",
    "gdf = gdf[['name', 'type', 'geometry']]\n",
    "\n",
    "# Save\n",
    "gdf.to_file(\"prague_tourism.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Saved {len(gdf)} points.\")"
   ],
   "id": "c19b7286f728c6e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Saved 5720 points.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T22:58:20.145021Z",
     "start_time": "2025-12-23T22:58:19.662899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Load raw listings\n",
    "df = pd.read_csv(\"listings.csv\")\n",
    "\n",
    "# Clean price column (remove $ and commas)\n",
    "if df['price'].dtype == 'O':\n",
    "    df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Filter: active listings only (reviewed in last 12 months)\n",
    "# This removes \"dead\" listings that skew statistics\n",
    "df = df[df['number_of_reviews_ltm'] > 0].copy()\n",
    "\n",
    "# Feature 1: Entire home\n",
    "df['is_entire_home'] = (df['room_type'] == 'Entire home/apt').astype(int)\n",
    "\n",
    "# Feature 2: Economy vs Luxury (Based on Percentiles)\n",
    "p25 = df['price'].quantile(0.25)\n",
    "p75 = df['price'].quantile(0.75)\n",
    "\n",
    "df['is_economy'] = (df['price'] <= p25).astype(int)\n",
    "df['is_luxury'] = (df['price'] >= p75).astype(int)\n",
    "\n",
    "# Create geometry\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Export only necessary columns\n",
    "cols = ['id', 'price', 'is_entire_home', 'is_economy', 'is_luxury', 'geometry']\n",
    "gdf[cols].to_file(\"listings_clean.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"Saved {len(gdf)} active listings.\")\n",
    "print(f\"Economy threshold: < {p25}\")\n",
    "print(f\"Luxury threshold: > {p75}\")"
   ],
   "id": "a6e7350c473c728d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\Michael\\AppData\\Local\\Temp\\ipykernel_24952\\2829959221.py:9: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 8098 active listings.\n",
      "Economy threshold: < 2086.0\n",
      "Luxury threshold: > 4720.75\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T22:59:08.454689Z",
     "start_time": "2025-12-23T22:58:20.194021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import ast\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Crime category codes\n",
    "VIOLENT = [1, 3, 5, 7, 8]\n",
    "BURGLARY = [18, 19, 20]\n",
    "THEFT = [35, 41, 43]\n",
    "DISORDER = [76, 111]\n",
    "\n",
    "# Load all geojson files manually (to fix list-column issues)\n",
    "files = glob.glob(\"2024*.geojson\")\n",
    "data_list = []\n",
    "\n",
    "print(f\"Merging {len(files)} files...\")\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'r', encoding='utf-8') as file:\n",
    "        raw = json.load(file)\n",
    "\n",
    "    # Extract attributes and geometry\n",
    "    df_attr = pd.json_normalize([feat['properties'] for feat in raw['features']])\n",
    "    geoms = [shape(feat['geometry']) for feat in raw['features']]\n",
    "\n",
    "    temp_gdf = gpd.GeoDataFrame(df_attr, geometry=geoms, crs=\"EPSG:4326\")\n",
    "    data_list.append(temp_gdf)\n",
    "\n",
    "gdf = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Filter valid crimes (Relevance 4 = confirmed crime scene)\n",
    "gdf = gdf[(gdf['relevance'] == 4) & (gdf['state'].isin([1, 2]))].copy()\n",
    "\n",
    "# Helper to map codes to names\n",
    "def get_category(val):\n",
    "    # Parse string to list if necessary\n",
    "    if isinstance(val, str):\n",
    "        try: val = ast.literal_eval(val)\n",
    "        except: val = []\n",
    "\n",
    "    # Check codes\n",
    "    for code in (val if isinstance(val, list) else []):\n",
    "        if code in VIOLENT: return \"Violent\"\n",
    "        if code in BURGLARY: return \"Burglary\"\n",
    "        if code in THEFT: return \"Theft\"\n",
    "        if code in DISORDER: return \"Disorder\"\n",
    "    return \"Other\"\n",
    "\n",
    "gdf['category'] = gdf['types'].apply(get_category)\n",
    "\n",
    "# Save\n",
    "gdf[['category', 'geometry']].to_file(\"crime.geojson\", driver=\"GeoJSON\")\n",
    "print(f\"Saved {len(gdf)} crimes. Summary:\")\n",
    "print(gdf['category'].value_counts())"
   ],
   "id": "9d591d07e5ee67e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 12 files...\n",
      "Saved 1282560 crimes. Summary:\n",
      "category\n",
      "Other       1138851\n",
      "Disorder      76601\n",
      "Theft         34819\n",
      "Burglary      21611\n",
      "Violent       10678\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T23:07:17.609880Z",
     "start_time": "2025-12-23T23:06:57.681160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# --- 1. LOAD BASE DATA ---\n",
    "print(\"Loading maps and stats...\")\n",
    "\n",
    "# Load districts (metric system)\n",
    "gdf = gpd.read_file(\"prague_districts_mest.geojson\").to_crs(\"EPSG:5514\")\n",
    "\n",
    "# Load population data\n",
    "df_socio = pd.read_csv(\"population.csv\", sep=\";\")\n",
    "\n",
    "# Load transport stops\n",
    "df_mhd = pd.read_csv(\"transport_stops.csv\").rename(columns={'public_transport_count': 'mhd_count'})\n",
    "\n",
    "# Fix naming inconsistencies\n",
    "def clean_name(name):\n",
    "    if pd.isna(name): return \"\"\n",
    "    return str(name).replace(\"\\xa0\", \" \").replace(\" - \", \"-\").replace(\"–\", \"-\").strip()\n",
    "\n",
    "gdf['district_name'] = gdf['district_name'].apply(clean_name)\n",
    "df_socio['district_name'] = df_socio['district_name'].apply(clean_name)\n",
    "if 'district_name' in df_mhd.columns:\n",
    "    df_mhd['district_name'] = df_mhd['district_name'].apply(clean_name)\n",
    "\n",
    "# Merge base tables\n",
    "gdf = gdf.merge(df_socio, on='district_name', how='left')\n",
    "gdf = gdf.merge(df_mhd, on='district_name', how='left')\n",
    "\n",
    "# Calc area & distance to center\n",
    "center = Point(-743000, -1043000) # Old Town Square\n",
    "gdf['area_km2'] = gdf.geometry.area / 1e6\n",
    "gdf['dist_center_km'] = gdf.geometry.centroid.distance(center) / 1000\n",
    "\n",
    "\n",
    "# --- 2. PROCESS SPATIAL DATA ---\n",
    "print(\"Processing spatial joins...\")\n",
    "\n",
    "def get_counts(filename):\n",
    "    try:\n",
    "        points = gpd.read_file(filename).to_crs(\"EPSG:5514\")\n",
    "        return gpd.sjoin(points, gdf[['district_name', 'geometry']], predicate=\"within\")\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# A) Airbnb\n",
    "airbnb = get_counts(\"listings_clean.geojson\")\n",
    "stats_ab = airbnb.groupby('district_name').agg({\n",
    "    'id': 'count', 'price': 'mean', 'is_economy': 'sum', 'is_luxury': 'sum', 'is_entire_home': 'sum'\n",
    "}).reset_index().rename(columns={'id': 'airbnb_count', 'price': 'price_avg', 'is_economy': 'airbnb_economy', 'is_luxury': 'airbnb_luxury', 'is_entire_home': 'airbnb_entire_home'})\n",
    "\n",
    "# B) Crime\n",
    "crime = get_counts(\"crime.geojson\")\n",
    "stats_cr_total = crime.groupby('district_name').size().reset_index(name='crime_total')\n",
    "# Pivot for crime types\n",
    "stats_cr_types = pd.crosstab(crime['district_name'], crime['category']).reset_index()\n",
    "stats_cr_types.columns = ['district_name'] + ['crime_' + c for c in stats_cr_types.columns if c != 'district_name']\n",
    "\n",
    "# C) Tourism / Nightlife (Filtered)\n",
    "poi = get_counts(\"prague_tourism.geojson\")\n",
    "# Filter irrelevant types\n",
    "ignore = ['fountain', 'dormitory', 'library', 'monastery', 'place_of_worship', 'planetarium', 'shelter', 'clock']\n",
    "poi = poi[~poi['type'].isin(ignore)]\n",
    "\n",
    "stats_poi_total = poi.groupby('district_name').size().reset_index(name='poi_count')\n",
    "# Pivot for POI types\n",
    "stats_poi_types = pd.crosstab(poi['district_name'], poi['type']).reset_index()\n",
    "stats_poi_types.columns = ['district_name'] + ['poi_' + c for c in stats_poi_types.columns if c != 'district_name']\n",
    "\n",
    "\n",
    "# --- 3. MERGE & CLEANUP ---\n",
    "print(\"Merging results...\")\n",
    "\n",
    "tables = [stats_ab, stats_cr_total, stats_cr_types, stats_poi_total, stats_poi_types]\n",
    "for table in tables:\n",
    "    gdf = gdf.merge(table, on='district_name', how='left')\n",
    "\n",
    "# Fill NaNs with 0 (except price)\n",
    "cols_fill = ['airbnb_count', 'mhd_count']\n",
    "cols_fill += [c for c in gdf.columns if c.startswith('crime_') or c.startswith('poi_')]\n",
    "gdf[cols_fill] = gdf[cols_fill].fillna(0)\n",
    "\n",
    "\n",
    "# --- 4. CALCULATE METRICS ---\n",
    "print(\"Feature engineering...\")\n",
    "\n",
    "# Target variable\n",
    "gdf['crime_rate'] = (gdf['crime_total'] / gdf['population']) * 1000\n",
    "\n",
    "# Densities (per km2)\n",
    "gdf['airbnb_density'] = gdf['airbnb_count'] / gdf['area_km2']\n",
    "gdf['airbnb_luxury_density'] = gdf['airbnb_luxury'] / gdf['area_km2']\n",
    "gdf['mhd_density'] = gdf['mhd_count'] / gdf['area_km2']\n",
    "gdf['poi_density'] = gdf['poi_count'] / gdf['area_km2']\n",
    "\n",
    "# Ratios (per capita)\n",
    "gdf['university_ratio'] = gdf['people_university'] / gdf['population']\n",
    "gdf['foreigner_ratio'] = gdf['foreigners'] / gdf['population']\n",
    "gdf['tourist_intensity'] = gdf['nights_non_residents'] / gdf['population']\n",
    "\n",
    "\n",
    "# --- 5. EXPORT ---\n",
    "# Organize columns\n",
    "cols_cr = [c for c in gdf.columns if c.startswith('crime_') and c not in ['crime_total', 'crime_rate']]\n",
    "cols_poi = [c for c in gdf.columns if c.startswith('poi_') and c != 'poi_count']\n",
    "\n",
    "final_cols = [\n",
    "    'district_name', 'population', 'area_km2', 'dist_center_km',\n",
    "    'crime_total', 'crime_rate',\n",
    "] + cols_cr + [\n",
    "    'airbnb_count', 'airbnb_density',\n",
    "    'airbnb_economy', 'airbnb_luxury', 'airbnb_luxury_density', 'airbnb_entire_home',\n",
    "    'price_avg',\n",
    "    'poi_count', 'poi_density'\n",
    "] + cols_poi + [\n",
    "    'nights_non_residents', 'tourist_intensity',\n",
    "    'foreigners', 'foreigner_ratio',\n",
    "    'people_university', 'university_ratio',\n",
    "    'unemployment',\n",
    "    'mhd_count', 'mhd_density'\n",
    "]\n",
    "\n",
    "gdf[final_cols].to_csv(\"final_dataset_mest.csv\", index=False)\n",
    "print(\"Done! Saved to final_dataset_mest.csv\")\n",
    "print(gdf[final_cols].head(3))"
   ],
   "id": "c644887a9ce0c6f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading maps and stats...\n",
      "Processing spatial joins...\n",
      "Merging results...\n",
      "Feature engineering...\n",
      "Done! Saved to final_dataset_mest.csv\n",
      "  district_name  population   area_km2  dist_center_km  crime_total  \\\n",
      "0       Praha 1       28921   5.538429        0.362492        14712   \n",
      "1      Praha 10      119110  18.599771        5.767105        10055   \n",
      "2      Praha 11       78410   9.793681        8.809829         9581   \n",
      "\n",
      "   crime_rate  crime_Burglary  crime_Disorder  crime_Other  crime_Theft  ...  \\\n",
      "0  508.696103             336            1085        11335         1781  ...   \n",
      "1   84.417765             631             518         7949          896  ...   \n",
      "2  122.191047             203             233         8694          421  ...   \n",
      "\n",
      "   poi_density  nights_non_residents  tourist_intensity  foreigners  \\\n",
      "0   302.432331               7023738         242.859445        8277   \n",
      "1    15.967939                523750           4.397196       28455   \n",
      "2     8.576959                301749           3.848348       17480   \n",
      "\n",
      "   foreigner_ratio  people_university  university_ratio  unemployment  \\\n",
      "0         0.286193               8057          0.278586          2.25   \n",
      "1         0.238897              32506          0.272907          2.43   \n",
      "2         0.222931              16361          0.208660          2.18   \n",
      "\n",
      "   mhd_count  mhd_density  \n",
      "0        274    49.472513  \n",
      "1        471    25.322893  \n",
      "2        223    22.769785  \n",
      "\n",
      "[3 rows x 39 columns]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T23:07:21.413153Z",
     "start_time": "2025-12-23T23:07:20.996546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "# Load dataset and map\n",
    "df = pd.read_csv(\"final_dataset_mest.csv\")\n",
    "gdf_map = gpd.read_file(\"prague_districts_mest.geojson\").to_crs(\"EPSG:5514\")\n",
    "\n",
    "# Merge data with geometry\n",
    "gdf = gdf_map.merge(df, on='district_name', how='left')\n",
    "\n",
    "cols_to_drop = [c for c in gdf.columns if c.endswith('_y')]\n",
    "gdf = gdf.drop(columns=cols_to_drop)\n",
    "gdf.columns = [c.replace('_x', '') for c in gdf.columns]\n",
    "\n",
    "# --- 2. DEFINE MAPPING (57 -> 22) ---\n",
    "# Mapping small cadastral districts to administrative districts\n",
    "mapping = {\n",
    "    'Praha 1': 'Praha 1',\n",
    "    'Praha 2': 'Praha 2',\n",
    "    'Praha 3': 'Praha 3',\n",
    "    'Praha 4': 'Praha 4', 'Praha-Kunratice': 'Praha 4',\n",
    "    'Praha 5': 'Praha 5', 'Praha-Slivenec': 'Praha 5',\n",
    "    'Praha 6': 'Praha 6', 'Praha-Lysolaje': 'Praha 6', 'Praha-Nebušice': 'Praha 6',\n",
    "    'Praha-Přední Kopanina': 'Praha 6', 'Praha-Suchdol': 'Praha 6',\n",
    "    'Praha 7': 'Praha 7', 'Praha-Troja': 'Praha 7',\n",
    "    'Praha 8': 'Praha 8', 'Praha-Březiněves': 'Praha 8',\n",
    "    'Praha-Dolní Chabry': 'Praha 8', 'Praha-Ďáblice': 'Praha 8',\n",
    "    'Praha 9': 'Praha 9',\n",
    "    'Praha 10': 'Praha 10',\n",
    "    'Praha 11': 'Praha 11', 'Praha-Křeslice': 'Praha 11',\n",
    "    'Praha-Šeberov': 'Praha 11', 'Praha-Újezd': 'Praha 11',\n",
    "    'Praha 12': 'Praha 12', 'Praha-Libuš': 'Praha 12',\n",
    "    'Praha 13': 'Praha 13', 'Praha-Řeporyje': 'Praha 13',\n",
    "    'Praha 14': 'Praha 14', 'Praha-Dolní Počernice': 'Praha 14',\n",
    "    'Praha 15': 'Praha 15', 'Praha-Dolní Měcholupy': 'Praha 15',\n",
    "    'Praha-Dubeč': 'Praha 15', 'Praha-Petrovice': 'Praha 15', 'Praha-Štěrboholy': 'Praha 15',\n",
    "    'Praha 16': 'Praha 16', 'Praha-Lipence': 'Praha 16',\n",
    "    'Praha-Lochkov': 'Praha 16', 'Praha-Velká Chuchle': 'Praha 16', 'Praha-Zbraslav': 'Praha 16',\n",
    "    'Praha 17': 'Praha 17', 'Praha-Zličín': 'Praha 17',\n",
    "    'Praha 18': 'Praha 18', 'Praha-Čakovice': 'Praha 18',\n",
    "    'Praha 19': 'Praha 19', 'Praha-Satalice': 'Praha 19', 'Praha-Vinoř': 'Praha 19',\n",
    "    'Praha 20': 'Praha 20',\n",
    "    'Praha 21': 'Praha 21', 'Praha-Běchovice': 'Praha 21',\n",
    "    'Praha-Klánovice': 'Praha 21', 'Praha-Koloděje': 'Praha 21',\n",
    "    'Praha 22': 'Praha 22', 'Praha-Benice': 'Praha 22',\n",
    "    'Praha-Kolovraty': 'Praha 22', 'Praha-Královice': 'Praha 22', 'Praha-Nedvězí': 'Praha 22'\n",
    "}\n",
    "\n",
    "gdf['admin_district'] = gdf['district_name'].map(mapping)\n",
    "gdf['admin_district'] = gdf['admin_district'].fillna(gdf['district_name'])\n",
    "\n",
    "# --- 3. PREPARE WEIGHTED DATA ---\n",
    "print(\"Calculating weighted values...\")\n",
    "\n",
    "# Prepare for weighted average: Value * Weight (Population)\n",
    "# This prevents small villages from skewing the average of a large district\n",
    "gdf['unemp_weighted'] = gdf['unemployment'] * gdf['population']\n",
    "gdf['price_weighted'] = gdf['price_avg'] * gdf['population']\n",
    "\n",
    "# --- 4. AGGREGATION ---\n",
    "print(\"Aggregating statistics...\")\n",
    "\n",
    "# Dissolve merges geometries and sums the data\n",
    "gdf_large = gdf.dissolve(by='admin_district', aggfunc='sum').reset_index()\n",
    "\n",
    "# --- 5. RECALCULATE RATES ---\n",
    "print(\"Recalculating rates and averages...\")\n",
    "\n",
    "gdf_large['area_km2'] = gdf_large.geometry.area / 10**6\n",
    "\n",
    "# 1. Weighted Averages\n",
    "gdf_large['unemployment'] = gdf_large['unemp_weighted'] / gdf_large['population']\n",
    "gdf_large['price_avg'] = gdf_large['price_weighted'] / gdf_large['population']\n",
    "\n",
    "# 2. Rates\n",
    "gdf_large['crime_rate'] = (gdf_large['crime_total'] / gdf_large['population']) * 1000\n",
    "\n",
    "# 3. Densities\n",
    "gdf_large['airbnb_density'] = gdf_large['airbnb_count'] / gdf_large['area_km2']\n",
    "gdf_large['mhd_density'] = gdf_large['mhd_count'] / gdf_large['area_km2']\n",
    "gdf_large['poi_density'] = gdf_large['poi_count'] / gdf_large['area_km2']\n",
    "\n",
    "if 'airbnb_luxury' in gdf_large.columns:\n",
    "    gdf_large['airbnb_luxury_density'] = gdf_large['airbnb_luxury'] / gdf_large['area_km2']\n",
    "\n",
    "# 4. Ratios\n",
    "gdf_large['university_ratio'] = gdf_large['people_university'] / gdf_large['population']\n",
    "gdf_large['foreigner_ratio'] = gdf_large['foreigners'] / gdf_large['population']\n",
    "gdf_large['tourist_intensity'] = gdf_large['nights_non_residents'] / gdf_large['population']\n",
    "\n",
    "# 5. Distance to center\n",
    "center_point = Point(-743000, -1043000)\n",
    "gdf_large['dist_center_km'] = gdf_large.geometry.centroid.distance(center_point) / 1000\n",
    "\n",
    "# Cleanup\n",
    "gdf_large = gdf_large.drop(columns=['unemp_weighted', 'price_weighted'])\n",
    "\n",
    "# --- 6. EXPORT ---\n",
    "# Rename for consistency\n",
    "gdf_large = gdf_large.rename(columns={'admin_district': 'district_name'})\n",
    "\n",
    "# Save\n",
    "gdf_large.to_csv(\"final_dataset_obvod.csv\", index=False)\n",
    "\n",
    "print(f\"Done! Aggregated to {len(gdf_large)} districts.\")\n",
    "print(gdf_large[['district_name', 'population', 'unemployment']].head())"
   ],
   "id": "cb1a2cb4a6d16e8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weighted values...\n",
      "Aggregating statistics...\n",
      "Recalculating rates and averages...\n",
      "Done! Aggregated to 22 districts.\n",
      "  district_name                                   district_name  population  \\\n",
      "0       Praha 1                                         Praha 1       28921   \n",
      "1      Praha 10                                        Praha 10      119110   \n",
      "2      Praha 11  Praha 11Praha-KřeslicePraha-ÚjezdPraha-Šeberov       86775   \n",
      "3      Praha 12                             Praha 12Praha-Libuš       70893   \n",
      "4      Praha 13                          Praha 13Praha-Řeporyje       72892   \n",
      "\n",
      "   unemployment  \n",
      "0      2.250000  \n",
      "1      2.430000  \n",
      "2      2.164435  \n",
      "3      2.393900  \n",
      "4      1.951725  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T23:11:05.671500Z",
     "start_time": "2025-12-23T23:11:05.592657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. LOAD DATA\n",
    "df_small = pd.read_csv(\"final_dataset_mest.csv\")   # 57 districts\n",
    "df_large = pd.read_csv(\"final_dataset_obvod.csv\")  # 22 districts\n",
    "\n",
    "# 2. REMOVE DUPLICATE COLUMNS\n",
    "# Sometimes merging creates 'col.1', we need to remove those\n",
    "def clean_columns(df):\n",
    "    cols_to_drop = [c for c in df.columns if '.1' in c]\n",
    "    if cols_to_drop:\n",
    "        print(f\"Dropping duplicate columns: {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    return df\n",
    "\n",
    "df_small = clean_columns(df_small)\n",
    "df_large = clean_columns(df_large)\n",
    "\n",
    "# 3. VERIFY SUMS (Consistency Check)\n",
    "# Totals (population, counts) must match exactly between datasets\n",
    "check_cols = ['population', 'airbnb_count', 'airbnb_luxury', 'crime_total']\n",
    "\n",
    "print(\"\\n--- SUM COMPARISON ---\")\n",
    "print(f\"{'Metric':<20} | {'Small (57)':<15} | {'Large (22)':<15} | {'Diff'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for col in check_cols:\n",
    "    sum_small = df_small[col].sum()\n",
    "    sum_large = df_large[col].sum()\n",
    "    diff = sum_small - sum_large\n",
    "    print(f\"{col:<20} | {sum_small:<15.0f} | {sum_large:<15.0f} | {diff}\")\n",
    "\n",
    "# 4. VERIFY WEIGHTED AVERAGES\n",
    "# Unemployment must be averaged by population, not simple mean\n",
    "print(\"\\n--- WEIGHTED AVERAGE CHECK (Unemployment) ---\")\n",
    "\n",
    "def calc_weighted_avg(df, val_col, weight_col):\n",
    "    return (df[val_col] * df[weight_col]).sum() / df[weight_col].sum()\n",
    "\n",
    "avg_small = calc_weighted_avg(df_small, 'unemployment', 'population')\n",
    "avg_large = calc_weighted_avg(df_large, 'unemployment', 'population')\n",
    "\n",
    "print(f\"Weighted Avg (Small): {avg_small:.4f}%\")\n",
    "print(f\"Weighted Avg (Large): {avg_large:.4f}%\")\n",
    "\n",
    "if abs(avg_small - avg_large) < 0.001:\n",
    "    print(\"SUCCESS: Weighted averages match!\")\n",
    "else:\n",
    "    print(\"WARNING: Averages do not match.\")\n",
    "\n",
    "# 5. EXPORT CLEAN FILES\n",
    "df_small.to_csv(\"final_dataset_mest.csv\", index=False)\n",
    "df_large.to_csv(\"final_dataset_obvod.csv\", index=False)\n",
    "print(\"\\nSaved clean datasets.\")"
   ],
   "id": "ca76fccf5f4273ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate columns: ['poi_density.1']\n",
      "Dropping duplicate columns: ['district_name.1', 'poi_density.1']\n",
      "\n",
      "--- SUM COMPARISON ---\n",
      "Metric               | Small (57)      | Large (22)      | Diff\n",
      "-----------------------------------------------------------------\n",
      "population           | 1397880         | 1397880         | 0\n",
      "airbnb_count         | 8098            | 8098            | 0.0\n",
      "airbnb_luxury        | 1827            | 1827            | 0.0\n",
      "crime_total          | 167386          | 167386          | 0\n",
      "\n",
      "--- WEIGHTED AVERAGE CHECK (Unemployment) ---\n",
      "Weighted Avg (Small): 2.4012%\n",
      "Weighted Avg (Large): 2.4012%\n",
      "SUCCESS: Weighted averages match!\n",
      "\n",
      "Saved clean datasets.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6aea701aba3e66dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
